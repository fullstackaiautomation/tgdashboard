# Story 4.6: Deep Work Session Insights & Optimization

## Status
Draft

## Story
**As** someone optimizing execution velocity,
**I want** insights from Deep Work session patterns,
**so that** I can improve focus, reduce context switching, and maximize productive output.

## Acceptance Criteria
1. Session analytics show: average session length, total sessions per day, longest session, shortest session
2. Context switching metric: number of different businesses/projects worked on per day (lower is better for deep focus)
3. Focus quality score: ratio of planned Deep Work sessions vs. unplanned/reactive work
4. Session completion tracking: % of sessions that achieved their stated goal/task
5. Interruption tracking: ability to mark Deep Work session as "interrupted" with reason, analytics show interruption frequency
6. Optimal session length analysis: compare productivity (tasks completed) across different session lengths to find personal sweet spot
7. Business context switching cost: visualize time lost when switching between businesses mid-day vs. dedicating full days to one business
8. Recommendation engine: "Based on your patterns, you're most productive with 90-minute sessions on Full Stack AI in the morning"
9. Deep Work streak tracking: consecutive days with at least one Deep Work session (motivational gamification)
10. Session notes analysis: ability to review notes across all sessions for a project to see progress narrative

## Tasks / Subtasks
- [ ] Task 1: Add session metadata columns to deep_work_sessions table (AC: 4, 5)
  - [ ] Add is_planned BOOLEAN column (default FALSE) - indicates if session was pre-scheduled
  - [ ] Add was_interrupted BOOLEAN column (default FALSE) - indicates if session was interrupted
  - [ ] Add interruption_reason TEXT column (nullable) - reason for interruption
  - [ ] Add goal_achieved BOOLEAN column (nullable) - whether session accomplished its goal
  - [ ] Add session_quality_rating INTEGER column (1-5 scale, nullable) - self-assessed quality
  - [ ] Create TypeScript DeepWorkSessionMetadata type
  - [ ] Create migration script: alter-deep-work-sessions-add-metadata.sql
  - [ ] Update useDeepWorkSessions hook to include metadata fields
- [ ] Task 2: Build session analytics calculation queries (AC: 1)
  - [ ] Create SQL function: get_session_analytics(user_id, date_range) returns JSONB
  - [ ] Calculate average session length: AVG(duration_minutes) FROM deep_work_sessions
  - [ ] Calculate total sessions per day: COUNT(*) GROUP BY DATE(start_time)
  - [ ] Find longest session: MAX(duration_minutes)
  - [ ] Find shortest session: MIN(duration_minutes)
  - [ ] Calculate median session length using PERCENTILE_CONT(0.5)
  - [ ] Group by time buckets: sessions <30min, 30-60min, 60-90min, 90-120min, >120min
  - [ ] Create src/components/insights/SessionAnalyticsCard.tsx to display metrics
- [ ] Task 3: Implement context switching detection and metrics (AC: 2, 7)
  - [ ] Create SQL function: calculate_context_switches(user_id, date) returns INTEGER
  - [ ] Logic: Count distinct business_id + life_area_id per day
  - [ ] Also count project switches: COUNT(DISTINCT project_id) per day
  - [ ] Calculate switching cost: Average 15-minute penalty per context switch
  - [ ] Query: Days with 1 business (focused) vs. days with 3+ businesses (fragmented)
  - [ ] Create src/components/insights/ContextSwitchingAnalysis.tsx
  - [ ] Display: "Today: 3 context switches (Full Stack → Health → Huge Capital)"
  - [ ] Visual: Timeline showing when switches occurred during the day
  - [ ] Insight: "You lose approximately 45 minutes per day to context switching"
  - [ ] Recommendation: "Try dedicating full days to one business for deeper focus"
- [ ] Task 4: Build focus quality score system (AC: 3)
  - [ ] Create SQL function: calculate_focus_quality_score(user_id, date_range) returns NUMERIC
  - [ ] Formula: (planned_sessions / total_sessions) * 100
  - [ ] Planned sessions: WHERE is_planned = TRUE
  - [ ] Unplanned sessions: WHERE is_planned = FALSE (reactive work)
  - [ ] Score ranges: 80-100% = Excellent, 60-79% = Good, 40-59% = Fair, <40% = Poor
  - [ ] Create src/components/insights/FocusQualityCard.tsx
  - [ ] Display: Large percentage with color-coded progress ring
  - [ ] Breakdown: "This week: 15 planned sessions, 5 unplanned (75% focus quality)"
  - [ ] Trend: Line chart showing focus quality over last 4 weeks
  - [ ] Insight: "Your focus quality improved by 15% this month - keep it up!"
- [ ] Task 5: Implement session completion tracking (AC: 4)
  - [ ] Add "Mark Goal Achieved" button to Deep Work timer stop interface
  - [ ] Modal on session end: "Did you accomplish your goal for this session? Yes / No / Partial"
  - [ ] Update goal_achieved column: TRUE, FALSE, or NULL (partial)
  - [ ] Create SQL function: calculate_completion_rate(user_id, date_range) returns NUMERIC
  - [ ] Formula: (sessions_with_goal_achieved / total_sessions) * 100
  - [ ] Create src/components/insights/CompletionRateCard.tsx
  - [ ] Display: "Goal Achievement Rate: 85% (34/40 sessions completed successfully)"
  - [ ] Filter by business/project: Show completion rate per business
  - [ ] Insight: "Full Stack AI: 90% completion, Huge Capital: 70% completion"
  - [ ] Recommendation: "Huge Capital sessions may need better goal definition or more time"
- [ ] Task 6: Create interruption tracking system (AC: 5)
  - [ ] Add "Mark Interrupted" button to running Deep Work timer
  - [ ] Modal: "Why was this session interrupted?" with predefined reasons
  - [ ] Interruption reasons: "Meeting", "Phone Call", "Urgent Request", "Personal", "Technical Issue", "Other"
  - [ ] Update was_interrupted = TRUE and set interruption_reason
  - [ ] Create SQL function: analyze_interruptions(user_id, date_range) returns JSONB
  - [ ] Calculate interruption frequency: (interrupted_sessions / total_sessions) * 100
  - [ ] Group by reason: COUNT(*) GROUP BY interruption_reason
  - [ ] Create src/components/insights/InterruptionAnalysis.tsx
  - [ ] Display: "Interruption Rate: 15% (6/40 sessions interrupted this week)"
  - [ ] Pie chart: Breakdown by interruption reason
  - [ ] Trend: Line chart showing interruptions per week over time
  - [ ] Insight: "Most interruptions due to Meetings (40%) - consider blocking focus time on calendar"
- [ ] Task 7: Build optimal session length analysis (AC: 6)
  - [ ] Create SQL function: analyze_optimal_session_length(user_id, business_id) returns TABLE
  - [ ] Group sessions by duration buckets: <30min, 30-60min, 60-90min, 90-120min, >120min
  - [ ] Calculate completion rate per bucket: AVG(goal_achieved) WHERE goal_achieved IS NOT NULL
  - [ ] Calculate tasks completed per bucket: COUNT(DISTINCT task_id)
  - [ ] Identify optimal bucket: Highest completion rate with meaningful sample size
  - [ ] Create src/components/insights/OptimalSessionLength.tsx
  - [ ] Bar chart: X-axis = duration buckets, Y-axis = completion rate %
  - [ ] Highlight optimal bucket: "Your sweet spot: 90-minute sessions (92% completion rate)"
  - [ ] Per-business analysis: Optimal length varies by business type
  - [ ] Recommendation: "Schedule Full Stack AI sessions for 90 minutes, Health sessions for 45 minutes"
- [ ] Task 8: Visualize business context switching cost (AC: 7)
  - [ ] Create SQL function: calculate_context_switching_cost(user_id, date_range) returns JSONB
  - [ ] Compare days with single-business focus vs. multi-business days
  - [ ] Metric 1: Average hours per business on focused days vs. fragmented days
  - [ ] Metric 2: Average completion rate on focused days vs. fragmented days
  - [ ] Metric 3: Estimated time lost: (context_switches * 15 minutes)
  - [ ] Create src/components/insights/ContextSwitchingCost.tsx
  - [ ] Comparison view: "Focused Days (1 business): 7.5h avg, 90% completion vs. Fragmented Days (3+ businesses): 5.2h avg, 65% completion"
  - [ ] Visual: Side-by-side bar chart showing productivity difference
  - [ ] Calendar heatmap: Color days by focus level (green = focused, yellow = moderate, red = fragmented)
  - [ ] Insight: "You're 25% more productive on focused days - aim for single-business days when possible"
- [ ] Task 9: Create AI-powered recommendation engine (AC: 8)
  - [ ] Create SQL function: generate_productivity_recommendations(user_id) returns JSONB array
  - [ ] Analyze patterns:
    - Optimal time of day per business: GROUP BY business_id, EXTRACT(HOUR FROM start_time), calculate completion_rate
    - Optimal session length per business: From Task 7 analysis
    - Optimal day structure: Single-business vs. multi-business days
    - Peak productive hours: Hours with highest completion rate
  - [ ] Generate recommendations using pattern matching logic
  - [ ] Create src/components/insights/ProductivityRecommendations.tsx
  - [ ] Display personalized recommendations:
    - "You're most productive with 90-minute sessions on Full Stack AI in the morning"
    - "Health sessions work best in early morning (6-8 AM) with 45-minute duration"
    - "Avoid scheduling Huge Capital after 3 PM - your completion rate drops by 30%"
    - "Try dedicating Tuesdays and Thursdays to Full Stack AI only for deeper focus"
  - [ ] Actionable CTAs: "Apply Recommendation" → pre-fill Daily schedule with suggested structure
  - [ ] Track recommendation adoption: Mark which recommendations were followed and measure impact
- [ ] Task 10: Implement Deep Work streak tracking and gamification (AC: 9)
  - [ ] Create SQL function: calculate_deep_work_streak(user_id) returns INTEGER
  - [ ] Algorithm: Count consecutive days with at least one Deep Work session
  - [ ] Start from today, iterate backwards until day with zero sessions
  - [ ] Store streak in cache (React Query) with daily refetch
  - [ ] Create src/components/insights/DeepWorkStreak.tsx
  - [ ] Display: "🔥 14-day Deep Work streak!" with flame emoji and large number
  - [ ] Progress bar showing current streak with milestone markers (7, 14, 30, 60, 100 days)
  - [ ] Achievements: "🏆 30-day streak achieved on [date]"
  - [ ] Best streak: "Your longest streak: 45 days (Jan 1 - Feb 14, 2025)"
  - [ ] Leaderboard (if multi-user): Compare streak with team/friends
  - [ ] Motivation: "Don't break the chain! Log a session today to continue your streak"
  - [ ] Integration: Prominent placement on Dashboard home page and Insights page
- [ ] Task 11: Build session notes review and progress narrative (AC: 10)
  - [ ] Create src/pages/ProjectSessionNotes.tsx (route: /projects/:projectId/sessions)
  - [ ] Query: SELECT * FROM deep_work_sessions WHERE project_id = ? ORDER BY start_time ASC
  - [ ] Display: Timeline view showing all sessions for a project chronologically
  - [ ] Each session card: Date, duration, business, task, labels, notes, goal_achieved status
  - [ ] Highlight notes: Show notes field prominently for narrative review
  - [ ] Filter: By date range, by goal_achieved status, by labels
  - [ ] Search: Full-text search across all session notes for project
  - [ ] Export: Generate project progress report PDF with all session notes
  - [ ] Progress narrative: AI-generated summary of project progress based on session notes (optional enhancement)
  - [ ] Integration: Link from Project detail page: "View All Sessions & Notes"
- [ ] Task 12: Create comprehensive Deep Work Insights dashboard (AC: all)
  - [ ] Create src/pages/DeepWorkInsights.tsx (route: /insights/deep-work)
  - [ ] Add navigation link: "Insights" in main navigation with lightbulb icon
  - [ ] Page layout:
    - Section 1: DeepWorkStreak (hero - motivational gamification)
    - Section 2: SessionAnalyticsCard (key metrics overview)
    - Section 3: FocusQualityCard + CompletionRateCard (side by side)
    - Section 4: ContextSwitchingAnalysis (full width)
    - Section 5: OptimalSessionLength (full width)
    - Section 6: InterruptionAnalysis (full width)
    - Section 7: ContextSwitchingCost (comparison view)
    - Section 8: ProductivityRecommendations (actionable insights)
  - [ ] Header actions: Date range selector, "Export Insights Report" button
  - [ ] Tab navigation: "Overview" | "Session Details" | "Recommendations"
  - [ ] Real-time updates: Insights refresh when new Deep Work sessions logged
  - [ ] Help tooltips: Explain each metric and how to improve it

## Dev Notes

### Previous Story Insights
**From Story 4.1:** [Source: docs/stories/4.1.deep-work-time-allocation-calculation.md]
- deep_work_sessions table established with business_id, life_area_id, project_id, task_id, labels, start_time, end_time, duration_minutes, notes
- Real-time sync infrastructure via useRealtimeSync
- CSV export utility pattern

**From Story 4.2:** [Source: docs/stories/4.2.business-time-investment-dashboard.md]
- Business-level time investment analysis
- Project time breakdown queries
- Historical trend visualizations

**From Story 4.3:** [Source: docs/stories/4.3.health-goal-time-monitoring.md]
- Streak tracking pattern for consecutive weeks meeting health targets
- Warning and alert systems for goal misses

**From Story 4.4:** [Source: docs/stories/4.4.time-allocation-visual-analytics.md]
- Comprehensive Time Analytics dashboard with Recharts visualizations
- Peak productivity time-of-day analysis
- Label-based time breakdown

**From Story 4.5:** [Source: docs/stories/4.5.time-allocation-targets-planning.md]
- Target vs. actual comparison patterns
- Recommendation engine framework
- Forecasting based on current patterns

**Key Technical Context:**
- This is the SIXTH and FINAL story in Epic 4 - adds deep insights layer for continuous optimization
- Session metadata (is_planned, was_interrupted, goal_achieved) enables quality tracking beyond just time tracking
- Context switching analysis quantifies the hidden cost of multitasking
- Recommendation engine uses pattern matching to provide personalized productivity insights
- Gamification (streaks, achievements) provides motivation for consistent Deep Work practice
- This story transforms raw time data into actionable intelligence

### Architecture Context

**Tech Stack:** [Source: docs/ui-architecture/2-frontend-tech-stack.md]
- React 19.1.1 + TypeScript 5.9.3
- TanStack Query 5.90.2 for insights data caching
- Recharts for all visualizations (bar charts, line charts, pie charts)
- date-fns 4.1.0 for date calculations
- Lucide React 0.544.0 for icons (Zap, Target, TrendingUp, Award)

**Database Schema Updates**
```sql
-- Add session metadata columns to deep_work_sessions table
ALTER TABLE deep_work_sessions ADD COLUMN is_planned BOOLEAN DEFAULT FALSE;
ALTER TABLE deep_work_sessions ADD COLUMN was_interrupted BOOLEAN DEFAULT FALSE;
ALTER TABLE deep_work_sessions ADD COLUMN interruption_reason TEXT DEFAULT NULL;
ALTER TABLE deep_work_sessions ADD COLUMN goal_achieved BOOLEAN DEFAULT NULL;
ALTER TABLE deep_work_sessions ADD COLUMN session_quality_rating INTEGER DEFAULT NULL
  CHECK (session_quality_rating >= 1 AND session_quality_rating <= 5);

-- Create indexes for insights queries
CREATE INDEX IF NOT EXISTS idx_deep_work_is_planned ON deep_work_sessions(is_planned);
CREATE INDEX IF NOT EXISTS idx_deep_work_was_interrupted ON deep_work_sessions(was_interrupted);
CREATE INDEX IF NOT EXISTS idx_deep_work_goal_achieved ON deep_work_sessions(goal_achieved);
CREATE INDEX IF NOT EXISTS idx_deep_work_user_date_business ON deep_work_sessions(user_id, DATE(start_time), business_id);

-- Add comments for documentation
COMMENT ON COLUMN deep_work_sessions.is_planned IS 'Whether session was pre-scheduled (TRUE) or reactive (FALSE)';
COMMENT ON COLUMN deep_work_sessions.was_interrupted IS 'Whether session was interrupted before natural completion';
COMMENT ON COLUMN deep_work_sessions.interruption_reason IS 'Reason for interruption if was_interrupted is TRUE';
COMMENT ON COLUMN deep_work_sessions.goal_achieved IS 'Whether session accomplished its intended goal (TRUE/FALSE/NULL for partial)';
COMMENT ON COLUMN deep_work_sessions.session_quality_rating IS 'Self-assessed quality rating (1-5 scale)';
```

**Deep Work Insights SQL Functions**
```sql
-- Get comprehensive session analytics
CREATE OR REPLACE FUNCTION get_session_analytics(
  p_user_id UUID,
  p_start_date DATE,
  p_end_date DATE
)
RETURNS JSONB AS $$
DECLARE
  v_result JSONB;
BEGIN
  SELECT jsonb_build_object(
    'total_sessions', COUNT(*),
    'avg_session_length_minutes', ROUND(AVG(duration_minutes), 0),
    'median_session_length_minutes', ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY duration_minutes), 0),
    'longest_session_minutes', MAX(duration_minutes),
    'shortest_session_minutes', MIN(duration_minutes),
    'total_deep_work_hours', ROUND(SUM(duration_minutes) / 60.0, 2),
    'avg_sessions_per_day', ROUND(COUNT(*)::NUMERIC / NULLIF(EXTRACT(DAY FROM p_end_date - p_start_date), 0), 1),
    'session_length_distribution', jsonb_build_object(
      'under_30min', COUNT(*) FILTER (WHERE duration_minutes < 30),
      '30_to_60min', COUNT(*) FILTER (WHERE duration_minutes >= 30 AND duration_minutes < 60),
      '60_to_90min', COUNT(*) FILTER (WHERE duration_minutes >= 60 AND duration_minutes < 90),
      '90_to_120min', COUNT(*) FILTER (WHERE duration_minutes >= 90 AND duration_minutes < 120),
      'over_120min', COUNT(*) FILTER (WHERE duration_minutes >= 120)
    )
  ) INTO v_result
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND DATE(start_time) >= p_start_date
    AND DATE(start_time) <= p_end_date;

  RETURN v_result;
END;
$$ LANGUAGE plpgsql STABLE;

-- Calculate context switches per day
CREATE OR REPLACE FUNCTION calculate_context_switches(
  p_user_id UUID,
  p_date DATE
)
RETURNS INTEGER AS $$
  SELECT COUNT(DISTINCT COALESCE(business_id::TEXT, life_area_id::TEXT)) - 1
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND DATE(start_time) = p_date;
$$ LANGUAGE SQL STABLE;

-- Calculate focus quality score
CREATE OR REPLACE FUNCTION calculate_focus_quality_score(
  p_user_id UUID,
  p_start_date DATE,
  p_end_date DATE
)
RETURNS NUMERIC AS $$
  SELECT
    CASE
      WHEN COUNT(*) = 0 THEN 0
      ELSE ROUND((COUNT(*) FILTER (WHERE is_planned = TRUE)::NUMERIC / COUNT(*)) * 100, 0)
    END
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND DATE(start_time) >= p_start_date
    AND DATE(start_time) <= p_end_date;
$$ LANGUAGE SQL STABLE;

-- Calculate completion rate
CREATE OR REPLACE FUNCTION calculate_completion_rate(
  p_user_id UUID,
  p_start_date DATE,
  p_end_date DATE
)
RETURNS NUMERIC AS $$
  SELECT
    CASE
      WHEN COUNT(*) FILTER (WHERE goal_achieved IS NOT NULL) = 0 THEN NULL
      ELSE ROUND((COUNT(*) FILTER (WHERE goal_achieved = TRUE)::NUMERIC /
        COUNT(*) FILTER (WHERE goal_achieved IS NOT NULL)) * 100, 0)
    END
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND DATE(start_time) >= p_start_date
    AND DATE(start_time) <= p_end_date;
$$ LANGUAGE SQL STABLE;

-- Analyze interruptions
CREATE OR REPLACE FUNCTION analyze_interruptions(
  p_user_id UUID,
  p_start_date DATE,
  p_end_date DATE
)
RETURNS JSONB AS $$
  SELECT jsonb_build_object(
    'total_sessions', COUNT(*),
    'interrupted_sessions', COUNT(*) FILTER (WHERE was_interrupted = TRUE),
    'interruption_rate', ROUND((COUNT(*) FILTER (WHERE was_interrupted = TRUE)::NUMERIC / NULLIF(COUNT(*), 0)) * 100, 0),
    'reasons', (
      SELECT jsonb_object_agg(interruption_reason, reason_count)
      FROM (
        SELECT interruption_reason, COUNT(*) as reason_count
        FROM deep_work_sessions
        WHERE user_id = p_user_id
          AND DATE(start_time) >= p_start_date
          AND DATE(start_time) <= p_end_date
          AND was_interrupted = TRUE
          AND interruption_reason IS NOT NULL
        GROUP BY interruption_reason
        ORDER BY reason_count DESC
      ) reasons
    )
  )
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND DATE(start_time) >= p_start_date
    AND DATE(start_time) <= p_end_date;
$$ LANGUAGE SQL STABLE;

-- Analyze optimal session length
CREATE OR REPLACE FUNCTION analyze_optimal_session_length(
  p_user_id UUID,
  p_business_id UUID,
  p_start_date DATE,
  p_end_date DATE
)
RETURNS TABLE(
  duration_bucket TEXT,
  session_count INTEGER,
  avg_completion_rate NUMERIC,
  tasks_completed INTEGER
) AS $$
  SELECT
    CASE
      WHEN duration_minutes < 30 THEN 'Under 30 min'
      WHEN duration_minutes < 60 THEN '30-60 min'
      WHEN duration_minutes < 90 THEN '60-90 min'
      WHEN duration_minutes < 120 THEN '90-120 min'
      ELSE 'Over 120 min'
    END as duration_bucket,
    COUNT(*)::INTEGER as session_count,
    ROUND(AVG(CASE WHEN goal_achieved = TRUE THEN 100 ELSE 0 END), 0) as avg_completion_rate,
    COUNT(DISTINCT task_id)::INTEGER as tasks_completed
  FROM deep_work_sessions
  WHERE user_id = p_user_id
    AND (p_business_id IS NULL OR business_id = p_business_id)
    AND DATE(start_time) >= p_start_date
    AND DATE(start_time) <= p_end_date
    AND goal_achieved IS NOT NULL
  GROUP BY duration_bucket
  ORDER BY duration_bucket;
$$ LANGUAGE SQL STABLE;

-- Calculate Deep Work streak
CREATE OR REPLACE FUNCTION calculate_deep_work_streak(p_user_id UUID)
RETURNS INTEGER AS $$
DECLARE
  v_current_streak INTEGER := 0;
  v_check_date DATE := CURRENT_DATE;
  v_session_count INTEGER;
BEGIN
  LOOP
    SELECT COUNT(*)
    INTO v_session_count
    FROM deep_work_sessions
    WHERE user_id = p_user_id
      AND DATE(start_time) = v_check_date;

    IF v_session_count > 0 THEN
      v_current_streak := v_current_streak + 1;
      v_check_date := v_check_date - INTERVAL '1 day';
    ELSE
      EXIT;
    END IF;

    -- Safety limit: check max 365 days
    IF v_current_streak >= 365 THEN
      EXIT;
    END IF;
  END LOOP;

  RETURN v_current_streak;
END;
$$ LANGUAGE plpgsql STABLE;

-- Generate productivity recommendations
CREATE OR REPLACE FUNCTION generate_productivity_recommendations(p_user_id UUID)
RETURNS JSONB AS $$
DECLARE
  v_recommendations JSONB := '[]'::JSONB;
  v_record RECORD;
BEGIN
  -- Find optimal time of day per business
  FOR v_record IN
    SELECT
      b.name as business_name,
      CASE
        WHEN EXTRACT(HOUR FROM dws.start_time) BETWEEN 6 AND 11 THEN 'morning'
        WHEN EXTRACT(HOUR FROM dws.start_time) BETWEEN 12 AND 17 THEN 'afternoon'
        WHEN EXTRACT(HOUR FROM dws.start_time) BETWEEN 18 AND 23 THEN 'evening'
        ELSE 'night'
      END as time_period,
      ROUND(AVG(CASE WHEN dws.goal_achieved = TRUE THEN 100 ELSE 0 END), 0) as completion_rate
    FROM deep_work_sessions dws
    JOIN businesses b ON dws.business_id = b.id
    WHERE dws.user_id = p_user_id
      AND dws.start_time >= NOW() - INTERVAL '30 days'
      AND dws.goal_achieved IS NOT NULL
    GROUP BY b.name, time_period
    HAVING COUNT(*) >= 5
    ORDER BY completion_rate DESC
    LIMIT 3
  LOOP
    v_recommendations := v_recommendations || jsonb_build_object(
      'type', 'optimal_time',
      'business', v_record.business_name,
      'time_period', v_record.time_period,
      'completion_rate', v_record.completion_rate,
      'message', format('You''re most productive on %s in the %s (% s%% completion rate)',
        v_record.business_name, v_record.time_period, v_record.completion_rate)
    );
  END LOOP;

  -- Add more recommendation types (omitted for brevity)

  RETURN v_recommendations;
END;
$$ LANGUAGE plpgsql STABLE;
```

**React Query Hooks Pattern**
```typescript
// src/hooks/useDeepWorkInsights.ts
import { useQuery } from '@tanstack/react-query';
import { supabase } from '@/lib/supabase';
import { format } from 'date-fns';

export const useSessionAnalytics = (dateRange: { start: Date; end: Date }) => {
  return useQuery({
    queryKey: ['session-analytics', dateRange],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('get_session_analytics', {
        p_user_id: user.id,
        p_start_date: format(dateRange.start, 'yyyy-MM-dd'),
        p_end_date: format(dateRange.end, 'yyyy-MM-dd'),
      });

      if (error) throw error;
      return data;
    },
    staleTime: 5 * 60 * 1000, // 5 minutes
  });
};

export const useFocusQualityScore = (dateRange: { start: Date; end: Date }) => {
  return useQuery({
    queryKey: ['focus-quality', dateRange],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('calculate_focus_quality_score', {
        p_user_id: user.id,
        p_start_date: format(dateRange.start, 'yyyy-MM-dd'),
        p_end_date: format(dateRange.end, 'yyyy-MM-dd'),
      });

      if (error) throw error;
      return data as number;
    },
  });
};

export const useCompletionRate = (dateRange: { start: Date; end: Date }) => {
  return useQuery({
    queryKey: ['completion-rate', dateRange],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('calculate_completion_rate', {
        p_user_id: user.id,
        p_start_date: format(dateRange.start, 'yyyy-MM-dd'),
        p_end_date: format(dateRange.end, 'yyyy-MM-dd'),
      });

      if (error) throw error;
      return data as number | null;
    },
  });
};

export const useInterruptionAnalysis = (dateRange: { start: Date; end: Date }) => {
  return useQuery({
    queryKey: ['interruption-analysis', dateRange],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('analyze_interruptions', {
        p_user_id: user.id,
        p_start_date: format(dateRange.start, 'yyyy-MM-dd'),
        p_end_date: format(dateRange.end, 'yyyy-MM-dd'),
      });

      if (error) throw error;
      return data;
    },
  });
};

export const useDeepWorkStreak = () => {
  return useQuery({
    queryKey: ['deep-work-streak'],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('calculate_deep_work_streak', {
        p_user_id: user.id,
      });

      if (error) throw error;
      return data as number;
    },
    staleTime: 60 * 60 * 1000, // 1 hour
  });
};

export const useProductivityRecommendations = () => {
  return useQuery({
    queryKey: ['productivity-recommendations'],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('generate_productivity_recommendations', {
        p_user_id: user.id,
      });

      if (error) throw error;
      return data;
    },
    staleTime: 24 * 60 * 60 * 1000, // 24 hours
  });
};
```

**Component Patterns**
```typescript
// src/components/insights/DeepWorkStreak.tsx
import { Flame } from 'lucide-react';
import { useDeepWorkStreak } from '@/hooks/useDeepWorkInsights';

export const DeepWorkStreak: React.FC = () => {
  const { data: streak, isLoading } = useDeepWorkStreak();

  if (isLoading) return <div>Loading streak...</div>;

  const milestones = [7, 14, 30, 60, 100];
  const nextMilestone = milestones.find(m => m > (streak || 0)) || 100;

  return (
    <div className="bg-gradient-to-r from-orange-50 to-red-50 rounded-lg shadow-lg p-6">
      <div className="flex items-center justify-between mb-4">
        <div className="flex items-center gap-3">
          <Flame className="w-12 h-12 text-orange-500" />
          <div>
            <div className="text-5xl font-bold text-orange-600">
              {streak} {streak === 1 ? 'day' : 'days'}
            </div>
            <div className="text-sm text-gray-600 mt-1">
              Deep Work Streak
            </div>
          </div>
        </div>
        {streak && streak >= 7 && (
          <div className="text-6xl animate-bounce">🏆</div>
        )}
      </div>

      {/* Progress to next milestone */}
      <div className="mb-2">
        <div className="flex justify-between text-sm text-gray-600 mb-1">
          <span>Next milestone: {nextMilestone} days</span>
          <span>{nextMilestone - (streak || 0)} days to go</span>
        </div>
        <div className="w-full bg-gray-300 rounded-full h-3">
          <div
            className="bg-orange-500 h-3 rounded-full transition-all duration-500"
            style={{ width: `${((streak || 0) / nextMilestone) * 100}%` }}
          />
        </div>
      </div>

      <div className="text-sm text-gray-700 mt-4">
        {streak === 0 && "Start logging Deep Work sessions to build your streak!"}
        {streak && streak < 7 && "Great start! Keep going to reach 7 days."}
        {streak && streak >= 7 && "Amazing consistency! Don't break the chain!"}
      </div>
    </div>
  );
};

// src/components/insights/FocusQualityCard.tsx
export const FocusQualityCard: React.FC<{ dateRange: DateRange }> = ({ dateRange }) => {
  const { data: score, isLoading } = useFocusQualityScore(dateRange);

  if (isLoading) return <div>Loading...</div>;

  const scoreColor = (score || 0) >= 80 ? 'text-green-600'
    : (score || 0) >= 60 ? 'text-blue-600'
    : (score || 0) >= 40 ? 'text-yellow-600'
    : 'text-red-600';

  const scoreLabel = (score || 0) >= 80 ? 'Excellent'
    : (score || 0) >= 60 ? 'Good'
    : (score || 0) >= 40 ? 'Fair'
    : 'Needs Improvement';

  return (
    <div className="bg-white rounded-lg shadow p-6">
      <h3 className="text-lg font-semibold mb-4">Focus Quality Score</h3>
      <div className={`text-6xl font-bold ${scoreColor} mb-2`}>
        {score || 0}%
      </div>
      <div className="text-sm text-gray-600 mb-4">{scoreLabel}</div>
      <div className="text-sm text-gray-700">
        This represents the ratio of planned vs. reactive work sessions.
        Higher scores indicate better focus and intentionality.
      </div>
    </div>
  );
};

// src/components/insights/ProductivityRecommendations.tsx
export const ProductivityRecommendations: React.FC = () => {
  const { data: recommendations, isLoading } = useProductivityRecommendations();

  if (isLoading) return <div>Loading recommendations...</div>;

  return (
    <div className="bg-white rounded-lg shadow p-6">
      <h3 className="text-lg font-semibold mb-4">Productivity Recommendations</h3>
      <div className="space-y-4">
        {recommendations?.map((rec: any, index: number) => (
          <div key={index} className="border-l-4 border-blue-500 pl-4 py-2">
            <div className="font-medium text-gray-900">{rec.message}</div>
            {rec.completion_rate && (
              <div className="text-sm text-gray-600 mt-1">
                Completion rate: {rec.completion_rate}%
              </div>
            )}
            <button className="mt-2 text-sm text-blue-600 hover:underline">
              Apply Recommendation →
            </button>
          </div>
        ))}
      </div>
      {(!recommendations || recommendations.length === 0) && (
        <div className="text-gray-500 text-center py-8">
          Log more Deep Work sessions to receive personalized recommendations
        </div>
      )}
    </div>
  );
};
```

**File Locations:**
- Update: supabase-tasks-hub-schema.sql (add metadata columns to deep_work_sessions)
- Create: supabase-deep-work-insights-functions.sql (SQL functions)
- Create: src/pages/DeepWorkInsights.tsx
- Create: src/pages/ProjectSessionNotes.tsx
- Create: src/hooks/useDeepWorkInsights.ts
- Create: src/components/insights/DeepWorkStreak.tsx
- Create: src/components/insights/SessionAnalyticsCard.tsx
- Create: src/components/insights/FocusQualityCard.tsx
- Create: src/components/insights/CompletionRateCard.tsx
- Create: src/components/insights/InterruptionAnalysis.tsx
- Create: src/components/insights/ContextSwitchingAnalysis.tsx
- Create: src/components/insights/OptimalSessionLength.tsx
- Create: src/components/insights/ContextSwitchingCost.tsx
- Create: src/components/insights/ProductivityRecommendations.tsx
- Update: src/components/deep-work/DeepWorkTimer.tsx (add interruption, goal achieved prompts)
- Update: src/App.tsx (add routes: /insights/deep-work, /projects/:projectId/sessions)

### Testing

**Testing Requirements:** [Source: docs/prd/technical-assumptions.md]
Manual testing with systematic verification (no automated test suite per PRD)

**Deep Work Session Insights Validation Workflow:**
1. **Database Schema Verification:**
   - Run ALTER TABLE to add metadata columns to deep_work_sessions
   - Verify columns: is_planned, was_interrupted, interruption_reason, goal_achieved, session_quality_rating
   - Create all SQL functions: get_session_analytics, calculate_focus_quality_score, etc.
   - Test SQL functions with sample data

2. **Session Metadata Capture Testing:**
   - Start Deep Work session, mark as "planned" (checkbox)
   - Stop session → modal appears: "Did you achieve your goal?"
   - Select "Yes" → verify goal_achieved = TRUE in database
   - Test interruption: Mid-session, click "Mark Interrupted" → select reason "Meeting"
   - Verify was_interrupted = TRUE, interruption_reason = "Meeting"

3. **Session Analytics Card Testing:**
   - Create 20 Deep Work sessions with varying lengths: 30min, 60min, 90min, 120min
   - Navigate to Deep Work Insights page
   - Verify SessionAnalyticsCard shows:
     - Total sessions: 20
     - Avg length: ~75 minutes
     - Longest: 120 min, Shortest: 30 min
     - Distribution: 5 sessions <30min, 8 sessions 30-60min, etc.

4. **Context Switching Analysis Testing:**
   - Create sessions on Monday: Full Stack (2h), Health (1h), Huge Capital (1.5h)
   - Run calculate_context_switches(user_id, Monday date)
   - Verify: 3 context switches detected
   - Verify ContextSwitchingAnalysis shows: "Today: 3 context switches"
   - Verify timeline visualization shows when switches occurred
   - Verify cost estimate: "~45 minutes lost to context switching"

5. **Focus Quality Score Testing:**
   - Create 15 planned sessions (is_planned = TRUE) and 5 unplanned sessions
   - Run calculate_focus_quality_score for date range
   - Verify score: 75% (15 planned / 20 total)
   - Verify FocusQualityCard shows: "75% - Good"
   - Create more planned sessions → verify score increases

6. **Completion Rate Testing:**
   - Create 10 sessions with goal_achieved = TRUE, 2 with FALSE, 3 with NULL
   - Run calculate_completion_rate
   - Verify: 83% completion rate (10 TRUE / 12 with non-NULL)
   - Test per-business: Full Stack 90%, Huge Capital 70%
   - Verify CompletionRateCard shows breakdown

7. **Interruption Analysis Testing:**
   - Create 6 interrupted sessions: 3 "Meeting", 2 "Phone Call", 1 "Technical Issue"
   - Total 40 sessions → interruption rate: 15%
   - Verify InterruptionAnalysis shows: "15% (6/40 sessions interrupted)"
   - Verify pie chart: Meeting 50%, Phone Call 33%, Technical Issue 17%
   - Verify insight: "Most interruptions due to Meetings (50%)"

8. **Optimal Session Length Testing:**
   - Create sessions across duration buckets with varying completion rates
   - 60-90min bucket: 15 sessions, 92% completion rate (highest)
   - Run analyze_optimal_session_length
   - Verify OptimalSessionLength highlights: "Your sweet spot: 60-90 minute sessions (92% completion)"
   - Test per-business: Full Stack optimal 90min, Health optimal 45min

9. **Deep Work Streak Testing:**
   - Create sessions for 14 consecutive days (at least 1 session per day)
   - Run calculate_deep_work_streak
   - Verify streak: 14 days
   - Verify DeepWorkStreak shows: "🔥 14 days - Deep Work Streak!"
   - Skip one day → verify streak resets to 0
   - Test milestone: Reach 30 days → verify achievement badge displayed

10. **Productivity Recommendations Testing:**
    - Create pattern: Full Stack sessions in morning (9-11 AM) have 95% completion rate
    - Full Stack sessions in afternoon (3-5 PM) have 65% completion rate
    - Run generate_productivity_recommendations
    - Verify recommendation: "You're most productive on Full Stack AI in the morning (95% completion rate)"
    - Verify actionable CTA: "Apply Recommendation" button
    - Click CTA → verify pre-fills Daily schedule with morning Full Stack session

11. **Project Session Notes Review Testing:**
    - Create 10 Deep Work sessions for Project X with detailed notes
    - Navigate to /projects/[projectId]/sessions
    - Verify timeline view shows all 10 sessions chronologically
    - Verify notes are prominently displayed for each session
    - Search notes for "bug fix" → verify filters to relevant sessions
    - Export as PDF → verify project progress report downloads

12. **Integration Testing:**
    - Full workflow: Monday, start planned Deep Work session on Full Stack AI at 9 AM
    - Work for 90 minutes → stop session, mark goal achieved
    - Verify session recorded with is_planned=TRUE, goal_achieved=TRUE, duration=90min
    - Check Insights dashboard → verify all metrics update:
      - Streak: +1 day
      - Focus quality: Increased
      - Completion rate: Increased
      - Session analytics: New 90min session added to distribution
    - Wednesday: Work on 3 different businesses → verify context switching analysis shows high switching
    - Friday: Mark session as interrupted ("Meeting") → verify interruption analysis updates
    - Week end: View recommendations → verify personalized insights based on week's patterns

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-07 | v1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record
### Agent Model Used
_To be populated by development agent_

### Debug Log References
_To be populated by development agent_

### Completion Notes List
_To be populated by development agent_

### File List
_To be populated by development agent_

## QA Results
_To be populated by QA agent_
