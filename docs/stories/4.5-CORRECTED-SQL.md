# Story 4.5 - Corrected SQL (Simple Approach)

> **Use this SQL instead of the inline SQL in Story 4.5**
> This version uses `deep_work_log.area` instead of `businesses`/`life_areas` tables

## Database Schema

```sql
-- Create area_time_targets table
CREATE TABLE IF NOT EXISTS area_time_targets (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  area TEXT NOT NULL CHECK (area IN ('Full Stack', 'S4', '808', 'Personal', 'Huge Capital', 'Golf', 'Health')),
  target_hours_per_week INTEGER NOT NULL CHECK (target_hours_per_week >= 0 AND target_hours_per_week <= 168),
  temporary_target_override INTEGER DEFAULT NULL,
  override_start_date DATE DEFAULT NULL,
  override_end_date DATE DEFAULT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, area)
);

CREATE INDEX idx_area_targets_user_area ON area_time_targets(user_id, area);
ALTER TABLE area_time_targets ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users manage own targets" ON area_time_targets
  USING (auth.uid() = user_id);
```

## SQL Functions

```sql
-- Get effective target (with temporary overrides)
CREATE OR REPLACE FUNCTION get_effective_target(
  p_regular_target INTEGER,
  p_temporary_override INTEGER,
  p_override_start DATE,
  p_override_end DATE
)
RETURNS INTEGER AS $$
BEGIN
  IF p_temporary_override IS NOT NULL
     AND p_override_start IS NOT NULL
     AND p_override_end IS NOT NULL
     AND CURRENT_DATE >= p_override_start
     AND CURRENT_DATE <= p_override_end THEN
    RETURN p_temporary_override;
  ELSE
    RETURN p_regular_target;
  END IF;
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- Get planned vs. actual for all 7 areas
CREATE OR REPLACE FUNCTION get_planned_vs_actual(
  p_user_id UUID,
  p_week_start DATE
)
RETURNS TABLE(
  area TEXT,
  target_hours INTEGER,
  actual_hours NUMERIC,
  percentage NUMERIC,
  status TEXT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    att.area,
    get_effective_target(
      att.target_hours_per_week,
      att.temporary_target_override,
      att.override_start_date,
      att.override_end_date
    ) as target_hours,
    COALESCE(ROUND(SUM(dwl.duration_minutes) / 60.0, 2), 0) as actual_hours,
    CASE
      WHEN get_effective_target(
        att.target_hours_per_week,
        att.temporary_target_override,
        att.override_start_date,
        att.override_end_date
      ) > 0 THEN
        ROUND((SUM(dwl.duration_minutes) / 60.0) / get_effective_target(
          att.target_hours_per_week,
          att.temporary_target_override,
          att.override_start_date,
          att.override_end_date
        ) * 100, 0)
      ELSE 0
    END as percentage,
    CASE
      WHEN get_effective_target(
        att.target_hours_per_week,
        att.temporary_target_override,
        att.override_start_date,
        att.override_end_date
      ) IS NULL THEN 'no_target'
      WHEN (SUM(dwl.duration_minutes) / 60.0) >= get_effective_target(
        att.target_hours_per_week,
        att.temporary_target_override,
        att.override_start_date,
        att.override_end_date
      ) THEN 'on_track'
      WHEN (SUM(dwl.duration_minutes) / 60.0) >= get_effective_target(
        att.target_hours_per_week,
        att.temporary_target_override,
        att.override_start_date,
        att.override_end_date
      ) * 0.8 THEN 'at_risk'
      ELSE 'behind'
    END as status
  FROM area_time_targets att
  LEFT JOIN deep_work_log dwl ON att.area = dwl.area
    AND dwl.user_id = p_user_id
    AND DATE(dwl.start_time) >= p_week_start
    AND DATE(dwl.start_time) < p_week_start + INTERVAL '7 days'
    AND dwl.end_time IS NOT NULL
  WHERE att.user_id = p_user_id
  GROUP BY att.area, att.target_hours_per_week, att.temporary_target_override,
    att.override_start_date, att.override_end_date;
END;
$$ LANGUAGE plpgsql STABLE;

-- Detect target mismatches (for recommendations)
CREATE OR REPLACE FUNCTION detect_target_mismatches(p_user_id UUID)
RETURNS JSONB AS $$
DECLARE
  v_recommendations JSONB := '[]'::JSONB;
  v_record RECORD;
  v_avg_actual NUMERIC;
  v_target INTEGER;
BEGIN
  FOR v_record IN
    SELECT
      att.area,
      att.target_hours_per_week as target,
      AVG(weekly_hours.hours) as avg_actual
    FROM area_time_targets att
    LEFT JOIN LATERAL (
      SELECT SUM(duration_minutes) / 60.0 as hours
      FROM deep_work_log
      WHERE area = att.area
        AND user_id = p_user_id
        AND start_time >= NOW() - INTERVAL '4 weeks'
        AND end_time IS NOT NULL
      GROUP BY DATE_TRUNC('week', start_time)
    ) weekly_hours ON true
    WHERE att.user_id = p_user_id
      AND att.target_hours_per_week IS NOT NULL
    GROUP BY att.area, att.target_hours_per_week
    HAVING COUNT(weekly_hours.hours) >= 3
  LOOP
    v_avg_actual := COALESCE(v_record.avg_actual, 0);
    v_target := v_record.target;

    IF v_avg_actual > v_target * 1.2 THEN
      v_recommendations := v_recommendations || jsonb_build_object(
        'area', v_record.area,
        'current_target', v_target,
        'suggested_target', CEIL(v_avg_actual),
        'avg_actual', ROUND(v_avg_actual, 1),
        'reason', 'consistent_over',
        'message', format('Averaging %.1fh/week but target is %sh - consider increasing to %sh',
          v_avg_actual, v_target, CEIL(v_avg_actual))
      );
    ELSIF v_avg_actual < v_target * 0.8 THEN
      v_recommendations := v_recommendations || jsonb_build_object(
        'area', v_record.area,
        'current_target', v_target,
        'suggested_target', CEIL(v_avg_actual),
        'avg_actual', ROUND(v_avg_actual, 1),
        'reason', 'consistent_under',
        'message', format('Averaging %.1fh/week but target is %sh - consider decreasing to %sh',
          v_avg_actual, v_target, CEIL(v_avg_actual))
      );
    END IF;
  END LOOP;

  RETURN v_recommendations;
END;
$$ LANGUAGE plpgsql STABLE;

-- Weekly forecast
CREATE OR REPLACE FUNCTION forecast_weekly_targets(
  p_user_id UUID,
  p_week_start DATE
)
RETURNS TABLE(
  area TEXT,
  target_hours INTEGER,
  actual_hours NUMERIC,
  days_elapsed INTEGER,
  projected_hours NUMERIC,
  status TEXT
) AS $$
DECLARE
  v_days_elapsed INTEGER;
BEGIN
  v_days_elapsed := EXTRACT(DOW FROM CURRENT_DATE) - EXTRACT(DOW FROM p_week_start);
  IF v_days_elapsed <= 0 THEN
    v_days_elapsed := 1;
  END IF;

  RETURN QUERY
  SELECT
    pva.area,
    pva.target_hours,
    pva.actual_hours,
    v_days_elapsed,
    ROUND((pva.actual_hours / v_days_elapsed) * 7, 2) as projected_hours,
    CASE
      WHEN pva.target_hours IS NULL THEN 'no_target'
      WHEN (pva.actual_hours / v_days_elapsed) * 7 >= pva.target_hours THEN 'on_track'
      WHEN (pva.actual_hours / v_days_elapsed) * 7 >= pva.target_hours * 0.8 THEN 'at_risk'
      ELSE 'unlikely'
    END as status
  FROM get_planned_vs_actual(p_user_id, p_week_start) pva;
END;
$$ LANGUAGE plpgsql STABLE;
```

## React Query Hooks

```typescript
// src/hooks/useTimePlanning.ts
import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';
import { supabase } from '@/lib/supabase';
import { startOfWeek, format } from 'date-fns';

export const usePlannedVsActual = (weekStart: Date) => {
  return useQuery({
    queryKey: ['planned-vs-actual', format(weekStart, 'yyyy-MM-dd')],
    queryFn: async () => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { data, error } = await supabase.rpc('get_planned_vs_actual', {
        p_user_id: user.id,
        p_week_start: format(weekStart, 'yyyy-MM-dd'),
      });

      if (error) throw error;
      return data as Array<{
        area: string;
        target_hours: number;
        actual_hours: number;
        percentage: number;
        status: 'no_target' | 'on_track' | 'at_risk' | 'behind';
      }>;
    },
    refetchInterval: 60 * 1000,
  });
};

export const useUpdateTimeTarget = () => {
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: async ({
      area,
      targetHours,
    }: {
      area: string;
      targetHours: number | null;
    }) => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { error } = await supabase
        .from('area_time_targets')
        .upsert({
          user_id: user.id,
          area,
          target_hours_per_week: targetHours,
        }, {
          onConflict: 'user_id,area'
        });

      if (error) throw error;
    },
    onSuccess: () => {
      queryClient.invalidateQueries({ queryKey: ['planned-vs-actual'] });
      queryClient.invalidateQueries({ queryKey: ['target-recommendations'] });
    },
  });
};

export const useSetTemporaryOverride = () => {
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: async ({
      area,
      overrideHours,
      startDate,
      endDate,
    }: {
      area: string;
      overrideHours: number;
      startDate: Date;
      endDate: Date;
    }) => {
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) throw new Error('Not authenticated');

      const { error } = await supabase
        .from('area_time_targets')
        .update({
          temporary_target_override: overrideHours,
          override_start_date: format(startDate, 'yyyy-MM-dd'),
          override_end_date: format(endDate, 'yyyy-MM-dd'),
        })
        .eq('user_id', user.id)
        .eq('area', area);

      if (error) throw error;
    },
    onSuccess: () => {
      queryClient.invalidateQueries({ queryKey: ['planned-vs-actual'] });
    },
  });
};
```

## Key Changes from Original Story 4.5

1. **No businesses/life_areas tables** - Uses `area_time_targets` table instead
2. **Simple area filter** - Queries `deep_work_log WHERE area = ?` instead of business_id/life_area_id joins
3. **7 hardcoded areas** - CHECK constraint ensures only valid areas
4. **Simpler functions** - No UNION ALL of businesses + life_areas, just one query
5. **Type changes** - Returns `area TEXT` instead of `type TEXT, id UUID, name TEXT`
6. **Update operations** - Direct UPSERT to `area_time_targets` instead of updating businesses/life_areas

## Migration Path

If implementing this story, use this corrected SQL file instead of the inline SQL in the main story file.
